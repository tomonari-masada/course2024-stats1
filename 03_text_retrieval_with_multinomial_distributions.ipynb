{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeti50+Lz7xwDDBOVtq1ao",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2024-stats1/blob/main/03_text_retrieval_with_multinomial_distributions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 多項分布を使った文書検索"
      ],
      "metadata": {
        "id": "ECnVmMCn7SqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 説明\n",
        "* 検索対象の各文書について、最尤推定で単語確率を求める。\n",
        "  * $\\phi_{d,w}$: 文書$d$における単語$w$の出現確率\n",
        "* クエリの尤度を、各文書について求めた単語確率を使って計算する。\n",
        "  * $n_{q,w}$: クエリ$q$における単語$w$の出現頻度\n",
        "  * このとき、文書$d$の単語確率を使ったクエリ$q$の対数尤度は、以下の通り。\n",
        "$$\\begin{align}\n",
        "L_q(d) = \\sum_w n_{q,w} \\log \\phi_{d,w}\n",
        "\\end{align}$$\n",
        "  * 上の式で、規格化定数の部分は省略している。（ランキングに関係しないため。）\n",
        "* このように計算されたクエリの尤度によって、検索対象の文書をソートする。\n",
        "  * $L_q(d)$が大きい順に、文書を検索結果として表示する。\n",
        "* 上記の方法では検索があまりうまくいかないことを確認する。\n",
        "  * 上の式を使うと、検索対象の文書に出現しない単語を含むクエリの尤度はゼロ（対数尤度はマイナス無限大）になる。"
      ],
      "metadata": {
        "id": "X-iu1PGr7U9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備"
      ],
      "metadata": {
        "id": "VrgoYRSB8LW6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWa9p9ODzp6V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import multinomial\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセット"
      ],
      "metadata": {
        "id": "bJrqfKPu8Maq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 20 newsgroupsコーパスを使う。\n",
        "* テストセットの文書一件一件を、クエリだと思う。\n",
        "* そして、訓練セットの文書の中から、類似文書を検索する。"
      ],
      "metadata": {
        "id": "495ze3X_l4xE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データセットのダウンロード"
      ],
      "metadata": {
        "id": "LKBGPwjOmEqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus, train_labels = fetch_20newsgroups(subset=\"train\", return_X_y=True)\n",
        "test_corpus, test_labels = fetch_20newsgroups(subset=\"test\", return_X_y=True)"
      ],
      "metadata": {
        "id": "-YJG99fWzv6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_corpus[0])"
      ],
      "metadata": {
        "id": "MiKkmczP0SKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_corpus), len(test_corpus)"
      ],
      "metadata": {
        "id": "UymRQ0zh0i_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 各文書での単語の出現回数を数える"
      ],
      "metadata": {
        "id": "zLUppB1kmGQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ここでは、訓練データで20文書未満にしか出現しない単語と、英語のストップワードとを、無視する。"
      ],
      "metadata": {
        "id": "0__v7p9FwsRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(min_df=20, stop_words=\"english\")\n",
        "X_train = vectorizer.fit_transform(train_corpus).toarray()\n",
        "X_test = vectorizer.transform(test_corpus).toarray()"
      ],
      "metadata": {
        "id": "bb8huq5W0YDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "R8jAYHgt09GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 語彙集合を取得する"
      ],
      "metadata": {
        "id": "_FvTqA4BmJZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = vectorizer.get_feature_names_out()\n",
        "print(vocabulary)"
      ],
      "metadata": {
        "id": "HDDmLD5m1SSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 最尤推定"
      ],
      "metadata": {
        "id": "0yMv87g68JwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 各文書を多項分布でモデリングする。\n",
        "* そして、最尤推定により、単語確率パラメータの値を推定する。"
      ],
      "metadata": {
        "id": "a5KkpfYlmNXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_probs = X_train / X_train.sum(axis=1).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "l8QqtXEj1hRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_probs.sum(axis=1)"
      ],
      "metadata": {
        "id": "xRd3TeER1zz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 対数尤度を求めるヘルパ関数"
      ],
      "metadata": {
        "id": "thSRYgWd8Erg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* テスト文書の対数尤度を、特定の訓練文書の単語確率を使って求めるヘルパ関数\n",
        "  * 訓練文書にない単語を含むテスト文書は、対数尤度がマイナス無限大になる\n",
        "  * クエリと共通する単語がない文書は、検索の対象にならなくなってしまう。"
      ],
      "metadata": {
        "id": "lzi6b7kImoOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_likelihood(x_test, x_train_prob):\n",
        "  # 多項分布の作成\n",
        "  rv = multinomial(x_test.sum(), x_train_prob)\n",
        "  # 対数尤度を確率質量関数を使って計算\n",
        "  return rv.logpmf(x_test)"
      ],
      "metadata": {
        "id": "mrTNOUMu17fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 検索の実行"
      ],
      "metadata": {
        "id": "0iYNZoj5n0xE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* クエリとして使うテスト文書の設定"
      ],
      "metadata": {
        "id": "hcOa-EgSwWfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_idx = 100"
      ],
      "metadata": {
        "id": "MDFgmswvwUvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* クエリ文書の内容を確認"
      ],
      "metadata": {
        "id": "CIopWIBroqTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_corpus[query_idx])"
      ],
      "metadata": {
        "id": "wL3I2nOCoZ-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " * 個々の訓練文書ごとに、クエリ文書の対数尤度を計算"
      ],
      "metadata": {
        "id": "roOAmuqvwcHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = list()\n",
        "for i in range(len(X_train)):\n",
        "  scores.append(log_likelihood(X_test[query_idx], X_train_probs[i]))\n",
        "scores = np.array(scores)\n",
        "\n",
        "# 降順にソート\n",
        "sorted_train_indices = (- scores).argsort()"
      ],
      "metadata": {
        "id": "dqyjvAz93jA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 実は、このままだと、すべての類似度が`-inf`になる。"
      ],
      "metadata": {
        "id": "y9n5bzYxc-K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(scores[sorted_train_indices] != - np.inf).sum()"
      ],
      "metadata": {
        "id": "wWBQc-7AcqoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* -infということは、確率ゼロということ。\n",
        "* つまり、いずれの検索対象の文書も、クエリの確率をゼロにしているということ。\n",
        "  * ちゃんと検索できていない、ということ。\n",
        "  * クエリに含まれる単語を全て含む訓練文書が、一つもない、ということ。"
      ],
      "metadata": {
        "id": "SRqe5QIulbT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 出現しないアイテムの確率をゼロにする最尤推定は、問題がありそう・・・。\n",
        "* どう対処すればいいのか？"
      ],
      "metadata": {
        "id": "z7WSFbyXl7Se"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## スムージング"
      ],
      "metadata": {
        "id": "AxV7fi2To5Px"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 検索性能を上げる一つのテクニック。\n",
        "* 検索対象の各文書について、単語確率を推定する前に、一律、小さな値を出現回数に加算する。"
      ],
      "metadata": {
        "id": "7Wq_I6pOAQzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0.01 という値の部分は、実際には、要チューニング。\n",
        "X_train = X_train + 0.01\n",
        "X_train_probs = X_train / X_train.sum(axis=1).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "1xKe491o5eje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 検索の実行"
      ],
      "metadata": {
        "id": "CXa-pxljtZMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 個々の訓練文書ごとに、クエリ文書のスコアを計算\n",
        "scores = list()\n",
        "for i in range(X_train.shape[0]):\n",
        "  scores.append(log_likelihood(X_test[query_idx], X_train_probs[i]))\n",
        "scores = np.array(scores)\n",
        "\n",
        "# 降順にソート\n",
        "sorted_train_indices = (- scores).argsort()"
      ],
      "metadata": {
        "id": "orGJTgOSpXrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_corpus[query_idx])"
      ],
      "metadata": {
        "id": "05cXC360pf7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_corpus[sorted_train_indices[0]])"
      ],
      "metadata": {
        "id": "5Xh9SKqgpinY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[query_idx], train_labels[sorted_train_indices[0]]"
      ],
      "metadata": {
        "id": "7zMDyYoKts2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores[sorted_train_indices[0]])"
      ],
      "metadata": {
        "id": "SxEhQpe1mGQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* -infにはなっていないようだ。"
      ],
      "metadata": {
        "id": "x7dkwLl3mJrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題\n",
        "スムージングを使った場合、テストセットの文書10件ぐらいについて、検索結果1位の訓練文書が、同じカテゴリに属しているかどうか、チェックする。"
      ],
      "metadata": {
        "id": "-9HP0L1Y4GAl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "veu4K7svpngo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}